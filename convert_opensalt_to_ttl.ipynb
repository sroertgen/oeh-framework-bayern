{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert opensalt to RDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "- Setup modules, paths, Node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from rdflib import Graph, Literal, Namespace, RDF, URIRef, BNode\n",
    "from rdflib.namespace import SKOS, DCTERMS, SDO\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "# path to curriculum data\n",
    "curriculum_xlsx = Path('./data/Lerhplan_all.xlsx')\n",
    "\n",
    "# create Node Class\n",
    "class Node:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.id = kwargs.get('_id')\n",
    "        self.type = kwargs.get('type')\n",
    "        self.name = kwargs.get('name')\n",
    "        self.description = kwargs.get('description')\n",
    "        # creator is of type object\n",
    "        self.creator = kwargs.get('creator')\n",
    "        self.publisher = kwargs.get('publisher')\n",
    "        self.courseCode = kwargs.get('courseCode')\n",
    "        self.educationalLevel = kwargs.get('educationalLevel')\n",
    "        self.educationalContext = kwargs.get('educationalContext')\n",
    "        self.level = kwargs.get('level')\n",
    "        self.license = kwargs.get('license')\n",
    "        # corresponds to \"hasPart\"\n",
    "        self.children = []\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "- we convert the curriculum file from xlsx to a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(curriculum_xlsx, sheet_name=1)\n",
    "data = df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now we have to adjust the names according to our schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CFItemType': nan,\n",
      " '_id': 'f2203a84-89f9-11ea-8413-0242ac1a0003',\n",
      " 'abbreviatedStatement': nan,\n",
      " 'conceptKeywords': nan,\n",
      " 'courseCode': 'D1/2',\n",
      " 'creator': {'id': 'https://www.isb.bayern.de/',\n",
      "             'name': 'Staatsinstitut für Schulqualität und Bildungsforschung '\n",
      "                     '(ISB)',\n",
      "             'type': 'Organization'},\n",
      " 'description': None,\n",
      " 'educationLevel': 1,\n",
      " 'educationalContext': {'inDefinedTermSet': 'http://w3id.org/openeduhub/vocabs/educationalContext/',\n",
      "                        'name': 'grundschule',\n",
      "                        'type': 'DefinedTerm',\n",
      "                        'url': 'http://w3id.org/openeduhub/vocabs/educationalContext/grundschule'},\n",
      " 'educationalLevel': {'inDefinedTermSet': 'http://w3id.org/openeduhub/vocabs/educationalLevel/',\n",
      "                      'name': '1',\n",
      "                      'type': 'DefinedTerm',\n",
      "                      'url': 'http://w3id.org/openeduhub/vocabs/educationalLevel/1'},\n",
      " 'fullStatement': 'Sprechen und Zuhören',\n",
      " 'humanCodingScheme': 'D1/2_grundschule_1_1',\n",
      " 'identifier': 'f2203a84-89f9-11ea-8413-0242ac1a0003',\n",
      " 'language': 'de',\n",
      " 'level': 0,\n",
      " 'license': 'http://cc0.com',\n",
      " 'listEnumeration': nan,\n",
      " 'name': 'Sprechen und Zuhören',\n",
      " 'notes': nan,\n",
      " 'publisher': {'id': 'https://www.isb.bayern.de/',\n",
      "               'name': 'Staatsinstitut für Schulqualität und Bildungsforschung '\n",
      "                       '(ISB)',\n",
      "               'type': 'Organization'},\n",
      " 'smartLevel': '1',\n",
      " 'type': 'Course'}\n"
     ]
    }
   ],
   "source": [
    "# set creator and publisher for curriculum\n",
    "\n",
    "creator = {\n",
    "    \"type\": \"Organization\",\n",
    "    \"id\": \"https://www.isb.bayern.de/\",\n",
    "    \"name\": \"Staatsinstitut für Schulqualität und Bildungsforschung (ISB)\"\n",
    "}\n",
    "\n",
    "publisher = {\n",
    "    \"type\": \"Organization\",\n",
    "    \"id\": \"https://www.isb.bayern.de/\",\n",
    "    \"name\": \"Staatsinstitut für Schulqualität und Bildungsforschung (ISB)\"\n",
    "}\n",
    "\n",
    "def split_item(item, delimiter, index):\n",
    "    try:\n",
    "        return item.split(delimiter)[index]\n",
    "    except IndexError:\n",
    "        # print(f\"index error at {item} at {index}\")\n",
    "        return None\n",
    "        pass\n",
    "\n",
    "for item in data:\n",
    "    item['_id'] = item['identifier']\n",
    "    item['type'] = \"Course\"\n",
    "    item['name'] = split_item(item['fullStatement'], ' - ', 0)\n",
    "    item['description'] = split_item(item['fullStatement'], ' - ', 1)\n",
    "    item['creator'] = creator\n",
    "    item['publisher'] = publisher\n",
    "    item['courseCode'] = split_item(item['humanCodingScheme'], '_', 0)\n",
    "    item['educationalLevel'] = {\n",
    "            \"type\": \"DefinedTerm\",\n",
    "            \"inDefinedTermSet\": \"http://w3id.org/openeduhub/vocabs/educationalLevel/\",\n",
    "            \"url\": \"http://w3id.org/openeduhub/vocabs/educationalLevel/\" + str(item['educationLevel']),\n",
    "            \"name\": str(item['educationLevel'])\n",
    "        }\n",
    "    item['educationalContext'] = {\n",
    "            \"type\": \"DefinedTerm\",\n",
    "            \"inDefinedTermSet\": \"http://w3id.org/openeduhub/vocabs/educationalContext/\",\n",
    "            \"url\": \"http://w3id.org/openeduhub/vocabs/educationalContext/\" + str(split_item(item['humanCodingScheme'], '_', 1)),\n",
    "            \"name\": str(split_item(item['humanCodingScheme'], '_', 1))\n",
    "        }\n",
    "    item['level'] =  item['smartLevel'].count('.')\n",
    "    item['license'] = 'http://cc0.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Node()\n",
    "\n",
    "try:\n",
    "    for record in data:\n",
    "        last = root\n",
    "        for _ in range(record['level']):\n",
    "            last = last.children[-1]\n",
    "\n",
    "        last.children.append(Node(\n",
    "            _id = record['_id'], \n",
    "            name = record['name'], \n",
    "            description = record['description'],\n",
    "            creator = record['creator'],\n",
    "            publisher = record['publisher'],\n",
    "            courseCode = record['courseCode'],\n",
    "            educationalLevel = record['educationalLevel'],\n",
    "            educationalContext = record['educationalContext'],\n",
    "            license = record['license'],\n",
    "            level = record['level']\n",
    "        ))\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    " # if not root node don't append educationalContext and educationalLevel to children\n",
    "# because these properties are inherited and can be reasoned from the\n",
    "# parent property\n",
    "def delete_from_children(root):\n",
    "    for child in root.children:\n",
    "        if child.level != 0:\n",
    "            try:\n",
    "                del(\n",
    "                    child.educationalContext, \n",
    "                    child.educationalLevel\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "        delete_from_children(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def print_tree(root, depth=0):\n",
    "    for child in root.children:\n",
    "        print('  ' * depth + '%r' % child)\n",
    "        print_tree(child, depth + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(print_tree(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the graph\n",
    "\n",
    "### `context.json`\n",
    "\n",
    "\n",
    "- `\"@container\": \"@set\"`:\n",
    "    - used to make even single values to be displayed as an array (see https://w3c.github.io/json-ld-syntax/#sets)\n",
    "- `\"@container\": \"@language\"`:\n",
    "    - is set to ensure easy language accessibility, when reading in files. Not sure yet how usefulit will be with german curricula, but it should be done in order to follow best practices. Primary language sub tags should be used, e.g. \"de\", \"en\"... (see https://w3c.github.io/json-ld-syntax/#string-internationalization)\n",
    "- courseCode:\n",
    "    - should be set to `\"@container\"`: [\"@set\", \"@language\"]`, but this is currently throwing an error in rdflib-jsonld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add relations?\n",
    "\n",
    "name_systematik = 'curriculum_bayern'\n",
    "\n",
    "filename_ttl = (Path.cwd() / 'data' / 'curriculum_bayern.ttl')\n",
    "filename_xml = (Path.cwd() / 'data' / 'curriculum_bayern.xml')\n",
    "filename_jsonld = (Path.cwd() / 'data' / 'curriculum_bayern.jsonld')\n",
    "\n",
    "# initialize graph\n",
    "g = Graph()\n",
    "\n",
    "# add OpenEduhub Namespace as OEH\n",
    "OEH = Namespace(\"http://w3id.org/openeduhub/vocabs/\")\n",
    "\n",
    "#define Namespace for curr\n",
    "curr = Namespace(\"http://example-perma-id.com/\" + name_systematik + \"/\")\n",
    "\n",
    "# define id for curriculum_model\n",
    "curriculum_model = URIRef(n)\n",
    "\n",
    "\n",
    "title = Literal(name_systematik, lang=\"de\")\n",
    "description = Literal(name_systematik, lang=\"de\")\n",
    "creator = Literal(\"<https://creator.com>\")\n",
    "\n",
    "# Bind a few prefix, namespace pairs for more readable output\n",
    "g.bind(\"sdo\", SDO)\n",
    "g.bind(\"oeh\", OEH)\n",
    "g.bind(\"curr\", curr)\n",
    "\n",
    "# Add triples to curriculum using store's add method.\n",
    "g.add( (curriculum_model, RDF.type, SDO.Course ) )\n",
    "g.add( (curriculum_model, SDO.name, title) )\n",
    "g.add( (curriculum_model, SDO.description, description) )\n",
    "g.add( (curriculum_model, SDO.creator, creator) )\n",
    "\n",
    "\n",
    "def add_items(root):\n",
    "    for item in root.children:\n",
    "\n",
    "        node = curr + URIRef(item.id)\n",
    "        node_name = Literal(item.name, lang=\"de\")\n",
    "        node_courseCode = Literal(item.courseCode, lang=\"de\")\n",
    "        node_courseCode2 = Literal(\"item.courseCode2\", lang=\"de\")\n",
    "        node_description = Literal(item.description, lang=\"de\")\n",
    "        node_licene = URIRef(item.license)\n",
    "        \n",
    "        # prepare blank node for creator\n",
    "        bNode_creator = BNode()\n",
    "        creator_type = SDO + URIRef(item.creator['type'])\n",
    "        creator_id = URIRef(item.creator['id'])\n",
    "        creator_name = Literal(item.creator['name'], lang=\"de\")\n",
    "\n",
    "        # prepare blank node for publisher\n",
    "        bNode_publisher = BNode()\n",
    "        publisher_type = SDO + URIRef(item.publisher['type'])\n",
    "        publisher_id = URIRef(item.publisher['id'])\n",
    "        publisher_name = Literal(item.publisher['name'], lang=\"de\")\n",
    "        \n",
    "        # prepare blank node for educationalLevel\n",
    "        bNode_educationalLevel = BNode()\n",
    "        educationalLevel_type = SDO + URIRef(item.educationalLevel['type'])\n",
    "        educationalLevel_name = Literal(item.educationalLevel['name'], lang=\"de\")\n",
    "        educationalLevel_url = URIRef(item.educationalLevel['url'])\n",
    "        educationalLevel_inDefinedTermSet = URIRef(item.educationalLevel['inDefinedTermSet'])\n",
    "\n",
    "        # prepare blank node for educationalContext\n",
    "        bNode_educationalContext = BNode()\n",
    "        educationalContext_type = SDO + URIRef(item.educationalContext['type'])\n",
    "        educationalContext_name = Literal(item.educationalContext['name'], lang=\"de\")\n",
    "        educationalContext_url = URIRef(item.educationalContext['url'])\n",
    "        educationalContext_inDefinedTermSet = URIRef(item.educationalContext['inDefinedTermSet'])\n",
    "\n",
    "\n",
    "        # add triples to the graph\n",
    "        g.add( (node, RDF.type, SDO.Course) )\n",
    "        g.add( (node, SDO.name, node_name))\n",
    "        g.add( (node, SDO.courseCode, node_courseCode) )\n",
    "        # TODO remove\n",
    "        g.add( (node, SDO.courseCode, node_courseCode2) )\n",
    "\n",
    "        g.add( (node, SDO.description, node_description) )\n",
    "        g.add( (node, SDO.license, node_licene) )\n",
    "        \n",
    "        # add bNode \"creator\"\n",
    "        g.add( (node, SDO.creator, bNode_creator) )\n",
    "        g.add( (bNode_creator, RDF.type, creator_type) )\n",
    "        g.add( (bNode_creator, SDO.name, creator_name) )\n",
    "        g.add( (bNode_creator, SDO.id, creator_id) )\n",
    "\n",
    "        # add bNode \"publisher\"\n",
    "        g.add( (node, SDO.publisher, bNode_publisher) )\n",
    "        g.add( (bNode_publisher, RDF.type, publisher_type) )\n",
    "        g.add( (bNode_publisher, SDO.name, publisher_name) )\n",
    "        g.add( (bNode_publisher, SDO.id, publisher_id) )\n",
    "        \n",
    "        # add bNode \"educationalLevel\"\n",
    "        g.add( (node, SDO.educationalLevel, bNode_educationalLevel) )\n",
    "        g.add( (bNode_educationalLevel, RDF.type, educationalLevel_type) )\n",
    "        g.add( (bNode_educationalLevel, SDO.name, educationalLevel_name) )\n",
    "        g.add( (bNode_educationalLevel, SDO.url, educationalLevel_url) )\n",
    "        g.add( (bNode_educationalLevel, SDO.inDefinedTermSet, educationalLevel_inDefinedTermSet))\n",
    "        \n",
    "        # add bNode \"educationalContext\"\n",
    "        g.add( (node, OEH.educationalContext, bNode_educationalContext) )\n",
    "        g.add( (bNode_educationalContext, RDF.type, educationalContext_type) )\n",
    "        g.add( (bNode_educationalContext, SDO.name, educationalContext_name) )\n",
    "        g.add( (bNode_educationalContext, SDO.url, educationalContext_url) )\n",
    "        g.add( (bNode_educationalContext, SDO.inDefinedTermSet, educationalContext_inDefinedTermSet))\n",
    "        \n",
    "        \n",
    "        if item.children != []:\n",
    "            for child in item.children:\n",
    "                g.add( (node, SDO.hasPart, n + URIRef(child.id)))\n",
    "                g.add( (n + URIRef(child.id), SDO.isPartOf, node))\n",
    "\n",
    "        add_items(item)\n",
    "            \n",
    "add_items(root)\n",
    "\n",
    "for child in root.children:\n",
    "    node = curr + URIRef(child.id)\n",
    "    g.add( (curriculum_model, SDO.hasPart, node))\n",
    "    g.add( (node, SDO.isPartOf, curriculum_model ))\n",
    "\n",
    "# load context file\n",
    "with open(\"context.json\") as json_file:\n",
    "    context = json.load(json_file)\n",
    "\n",
    "\n",
    "output_turtle = g.serialize(format='turtle').decode(\"utf-8\")\n",
    "output_xml = g.serialize(format='xml').decode(\"utf-8\")\n",
    "output_jsonld = g.serialize(format='json-ld', context=context).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def write_file(filename, data):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(data)\n",
    "        f.close()\n",
    "\n",
    "write_file(filename_ttl, output_turtle)\n",
    "write_file(filename_xml, output_xml)\n",
    "write_file(filename_jsonld, output_jsonld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare json files to use with visjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] iterate over graph with .triples function: https://rdflib.readthedocs.io/en/stable/intro_to_graphs.html#basic-triple-matching\n",
    "- [ ] does visjs accept strings as IDs?\n",
    "- [ ] write a write file function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create files just containing the nodes and edges\n",
    "\n",
    "- create nodes and edges using functions (-> do it functional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNodesAndEdges(graph):\n",
    "    nodes = []\n",
    "    edges = []\n",
    "\n",
    "    for s in g.subjects(RDF.type, SDO.Course):\n",
    "        name = g.value(s, SDO.name).value\n",
    "\n",
    "        nodes.append({\n",
    "            \"id\": s.toPython(),\n",
    "            \"label\": name\n",
    "        })\n",
    "        for o in g.objects(s, SDO.hasPart):\n",
    "            edges.append({\n",
    "                \"from\": s.toPython(),\n",
    "                \"to\": o\n",
    "            })\n",
    "    return nodes, edges\n",
    "\n",
    "nodes, edges = createNodesAndEdges(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write nodes and edges files for visjs\n",
    "\n",
    "id can also be strings according to doc: https://visjs.github.io/vis-network/docs/network/nodes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_nodes = Path.cwd() / \"data\" / \"curriculum_bayern_nodes_visjs.json\"\n",
    "filename_edges = Path.cwd() / \"data\" / \"curriculum_bayern_edges_visjs.json\"\n",
    "\n",
    "def write_json(filename, data):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "write_json(filename_nodes, nodes)\n",
    "write_json(filename_edges, edges)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdf",
   "language": "python",
   "name": "rdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "convert_opensalt_to_ttl.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
